# AI Trip Guide - Explorador de Viagens com IA

Projeto de portfÃ³lio que utiliza **LLMs open-source** para processar transcriÃ§Ãµes de vÃ­deos reais do YouTube sobre destinos de viagem e gerar respostas Ãºteis para o planejamento de roteiros.

![Python Version](https://img.shields.io/badge/Python-3.12%2B-blue)
![Streamlit](https://img.shields.io/badge/Streamlit-1.48.0-orange)
![License](https://img.shields.io/badge/license-MIT-green)
![AI Trip Guide Banner](src/images/cover.png)

---

## ğŸ¯ Objetivo
Criar uma aplicaÃ§Ã£o prÃ¡tica que aproveite **Modelos de Linguagem de CÃ³digo Aberto** para organizar, resumir e explorar informaÃ§Ãµes de viagens, inspirada na minha prÃ³pria experiÃªncia planejando uma viagem ao Chile (Santiago e regiÃµes de neve). O projeto combina:

- IA generativa para responder com base no contexto dos vÃ­deos.
- Engenharia de dados para processar e estruturar informaÃ§Ãµes de vÃ­deos e textos.
- NLP (Processamento de Linguagem Natural) para gerar resumos, classificar temas e responder perguntas sobre o destino.
- Interfaces interativas com Streamlit, permitindo uma exploraÃ§Ã£o intuitiva e dinÃ¢mica do conteÃºdo de viagem.

---

## ğŸ§± Arquitetura do Projeto
Para compreender a arquitetura do projeto, Ã© necessÃ¡rio primeiramente entender que ele possui tanto modo local como modo cloud.

Modo local: Roda no prÃ³prio computador do usuÃ¡rio e necessita de uma placa de vÃ­deo com ao menos 8GB. 

Modo cloud: Roda sem depender de recursos locais, utilizando o Gemini como um agente que responde as perguntas do  usuÃ¡rio, baseando-se no conteÃºdo dos vÃ­deos.

### Arquitetura do Projeto no modo Cloud

[Diagrama de fluxo do projeto modo Cloud](src/images/diagram_pt_cloud.png)

Fluxo resumido:
1. Busca de vÃ­deos no YouTubeAPI por destino.
2. ExtraÃ§Ã£o, transcriÃ§Ã£o e resumo via **Gemini**.
3. ClassificaÃ§Ã£o de blocos por tema.
5. CriaÃ§Ã£o de Ã­ndice vetorial local com **LlamaIndex**.
6. UsuÃ¡rio faz perguntas sobre o local
7. Tema da pergunta Ã© identificado **Gemini 2.5 flash**.
8. Contexto Ã© filtrado do vectordatabase **LlamaIndex**.
6. Respostas dinÃ¢micas com o modelo **Gemini 2.5 flash**.

### Arquitetura do Projeto no modo Local

[Diagrama de fluxo do projeto modo Local](src/images/diagram_pt_local.png)

Fluxo resumido:
1. Busca de vÃ­deos no YouTube por destino.
2. ExtraÃ§Ã£o e transcriÃ§Ã£o de Ã¡udio via **Whisper**.
3. PrÃ©-processamento e segmentaÃ§Ã£o de texto.
4. ClassificaÃ§Ã£o de blocos por tema.
5. CriaÃ§Ã£o de Ã­ndice vetorial local com **LlamaIndex**.
6. Respostas dinÃ¢micas com o modelo **Mistral**.

---

## ğŸ” Funcionalidades
Modo Cloud:
Uma das maiores vantagens do projeto Ã© a possibilidade de rodar em **modo cloud**, sem depender de GPUs locais.  
Nesse modo, o motor de geraÃ§Ã£o de respostas nÃ£o Ã© o **Mistral local**, mas sim a **Gemini API (Google AI)**.

### ğŸ”‘ Como funciona
1. As transcriÃ§Ãµes de vÃ­deos continuam sendo processadas e indexadas com **LlamaIndex**.
2. O Ã­ndice pode ser armazenado no Localmente ou no **S3** (ou outro storage remoto), evitando reprocessar a cada execuÃ§Ã£o.
3. Quando o usuÃ¡rio faz uma pergunta, o app envia o **contexto relevante do Ã­ndice** para a **Gemini API**.
4. A Gemini gera a resposta baseada no contexto enviado e retorna para a interface Streamlit.

### ğŸŒ BenefÃ­cios do modo Cloud
- **Escalabilidade** â†’ nÃ£o depende da GPU local, roda em qualquer instÃ¢ncia cloud.
- **Menor custo de infra** â†’ usa apenas API calls (de graÃ§a  atÃ© 60 requisiÃ§Ãµes por segundo).
- **IntegraÃ§Ã£o simples** â†’ basta configurar a variÃ¡vel `GEMINI_API_KEY` no `.env` ou nas secrets do Streamlit Cloud.
- **Mesma interface** â†’ o usuÃ¡rio final nÃ£o percebe diferenÃ§a: as respostas sÃ£o geradas da mesma forma.

- ğŸ” Busca automÃ¡tica de vÃ­deos do YouTube a partir de um destino informado.
- ğŸ™ï¸ TranscriÃ§Ã£o e resumo usando o GeminiAPI.
- ğŸ§  ClassificaÃ§Ã£o temÃ¡tica automÃ¡tica.
- ğŸ—ƒï¸ IndexaÃ§Ã£o vetorial com **LlamaIndex** e embeddings locais.
- ğŸ¤– GeraÃ§Ã£o de respostas contextualizadas com **Gemini 2.5 flash**.
- ğŸ“Š Painel de anÃ¡lise de temas mais recorrentes.
- ğŸ“ ExportaÃ§Ã£o das conversas em PDF.
- âš¡ Cache local de respostas para acelerar reconsultas.

### âš™ï¸ ConfiguraÃ§Ã£o
No `.env` adicione:
- YOUTUBE_API_KEY=sua_chave_youtube
- GEMINI_API_KEY=sua_chave_gemini

Modo Local:
- ğŸ” Busca automÃ¡tica de vÃ­deos do YouTube a partir de um destino informado.
- ğŸ™ï¸ TranscriÃ§Ã£o do Ã¡udio com Whisper.
- âœ‚ï¸ DivisÃ£o inteligente de blocos de texto.
- ğŸ§  ClassificaÃ§Ã£o temÃ¡tica automÃ¡tica.
- ğŸ—ƒï¸ IndexaÃ§Ã£o vetorial com **LlamaIndex** e embeddings locais.
- ğŸ¤– GeraÃ§Ã£o de respostas contextualizadas com **Mistral 7B Instruct**.
- ğŸ“Š Painel de anÃ¡lise de temas mais recorrentes.
- ğŸ“ ExportaÃ§Ã£o das conversas em PDF.
- âš¡ Cache local de respostas para acelerar reconsultas.

---

## ğŸ§  Modelos Utilizados

No modo Cloud:
- **TranscriÃ§Ã£o**: [`Gemini/Gemini 2.5 Flash`](https://gemini.google.com/)
- **ClassificaÃ§Ã£o de temas**: [`Gemini/Gemini 2.5 Flash`](https://gemini.google.com/)
- **GeraÃ§Ã£o de respostas**: [`Gemini/Gemini 2.5 Flash`](https://gemini.google.com/)
- **Embeddings**: [`gemini-embedding-001`](https://ai.google.dev/gemini-api/docs/embeddings?hl=pt-br)


No modo Local:
- **TranscriÃ§Ã£o**: [`openai/whisper-medium`](https://github.com/openai/whisper)
- **ClassificaÃ§Ã£o de temas**: [`facebook/bart-large-mnli`](https://huggingface.co/facebook/bart-large-mnli)
- **GeraÃ§Ã£o de respostas**: [`mistralai/Mistral-7B-Instruct-v0.2`](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2) (carregado via Hugging Face Transformers, com suporte a GPU e quantizaÃ§Ã£o `bitsandbytes`)
- **Embeddings**: [`sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2)

---

## ğŸ“– Detalhe: `mistral_llm.py`

Este mÃ³dulo encapsula a lÃ³gica para:
- Carregar o modelo **Gemini 2.5 Flash** caso use o modo 'cloud'.
- Carregar o modelo **Mistral 7B Instruct** caso use o modo 'local'.
- Configurar aceleraÃ§Ã£o por GPU (CUDA) quando disponÃ­vel.
- Definir parÃ¢metros de geraÃ§Ã£o de texto (temperatura, top_p, repetiÃ§Ã£o etc.).
- Criar a funÃ§Ã£o `gerar_resposta(prompt)` que recebe um prompt e retorna a resposta do modelo.

Ou seja, Ã© o coraÃ§Ã£o da etapa de **perguntas e respostas** do projeto.

---

## ğŸ–¼ï¸ Exemplo de Uso

### Link para testar o projeto
VocÃª pode testar o projeto diretamente pelo streamlitcloud clicando no link abaixo
- **Link da AplicaÃ§Ã£o**: [`AI Trip Guide`](https://ai-trip-guide-8t4ghrfpjlc6e9gxhmk7lw.streamlit.app/)

---

### ğŸ” 1. UsuÃ¡rio escolhe um destino e faz uma pergunta
![Escolha de tema e pergunta](src/images/demo/demo_1.png)

### ğŸ¤– 2. Resposta contextualizada com base nos vÃ­deos analisados
![Resposta da IA](src/images/demo/demo_2.png)

### ğŸ“Š 3. VisualizaÃ§Ã£o analÃ­tica dos dados processados
![VisualizaÃ§Ã£o analÃ­tica](src/images/demo/demo_3.png)

---

## ğŸš€ Como Executar Localmente

1. Clone este repositÃ³rio:
```bash
git clone https://github.com/seuusuario/ai-trip-guide.git
cd ai-trip-guide
